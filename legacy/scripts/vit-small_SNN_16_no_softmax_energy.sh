CUDA_VISIBLE_DEVICES=1 python -m torch.distributed.launch --nproc_per_node=1 --master_port='29501' main_finetune.py \
    --accum_iter 4 \
    --batch_size 8 \
    --model vit_small_patch16 \
    --finetune /home/kang_you/SpikeZIP_transformer/output/no_myquan_output/T-SNN_vit_small_patch16_imagenet_relu_QANN_QAT_act8_weightbit32/checkpoint-199.pth \
    --resume /home/kang_you/SpikeZIP_transformer/output/no_myquan_output/T-SNN_vit_small_patch16_imagenet_relu_QANN_QAT_act8_weightbit32/checkpoint-199.pth \
    --epochs 100 \
    --blr 3.536e-4 --layer_decay 0.65 \
    --weight_decay 0.05 --drop_path 0.1 --mixup 0.8 --cutmix 1.0 --reprob 0.25 \
    --dist_eval --data_path /data1/ImageNet/ --output_dir /home/kang_you/SpikeZIP_transformer/output/no_softmax --log_dir /home/kang_you/SpikeZIP_transformer/output/no_softmax \
    --mode "SNN"  --remove_softmax --act_layer relu --eval --energy_eval --time_step 15 --encoding_type analog --level 8 --define_params --mean 0.5 0.5 0.5 --std 0.5 0.5 0.5